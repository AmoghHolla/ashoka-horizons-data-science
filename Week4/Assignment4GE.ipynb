{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42db441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the first 5 rows of X:\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "\n",
      "First 5 things in y (target):\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int64\n",
      "\n",
      "Shape of X is: (569, 30)\n",
      "Shape of y is: (569,)\n",
      "\n",
      "How many 0s and 1s in y:\n",
      "target\n",
      "1    357\n",
      "0    212\n",
      "Name: count, dtype: int64\n",
      "\n",
      "What the targets mean:\n",
      "{np.str_('malignant'): 0, np.str_('benign'): 1}\n",
      "\n",
      "Some info about this data:\n",
      "- We have 569 samples (rows)\n",
      "- There are 30 features (columns)\n",
      "- The types of features are: [dtype('float64')]\n",
      "- The target classes are: [np.str_('malignant'), np.str_('benign')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "\n",
    "X = pd.DataFrame(cancer.data, columns=cancer.feature_names)\n",
    "\n",
    "\n",
    "y = pd.Series(cancer.target, name='target')\n",
    "\n",
    "\n",
    "print(\"Here are the first 5 rows of X:\")\n",
    "print(X.head())\n",
    "\n",
    "\n",
    "print(\"\\nFirst 5 things in y (target):\")\n",
    "print(y.head())\n",
    "\n",
    "\n",
    "print(\"\\nShape of X is:\", X.shape)\n",
    "print(\"Shape of y is:\", y.shape)\n",
    "\n",
    "\n",
    "print(\"\\nHow many 0s and 1s in y:\")\n",
    "print(y.value_counts())\n",
    "\n",
    "\n",
    "print(\"\\nWhat the targets mean:\")\n",
    "print(dict(zip(cancer.target_names, [0, 1])))\n",
    "\n",
    "\n",
    "print(\"\\nSome info about this data:\")\n",
    "print(\"- We have\", X.shape[0], \"samples (rows)\")\n",
    "print(\"- There are\", X.shape[1], \"features (columns)\")\n",
    "print(\"- The types of features are:\", X.dtypes.unique())\n",
    "print(\"- The target classes are:\", list(cancer.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eae79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (455, 30)\n",
      "X_test shape: (114, 30)\n",
      "Y_train shape: (455,)\n",
      "Y_test shape: (114,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"Y_train shape:\", Y_train.shape)\n",
    "print(\"Y_test shape:\", Y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4896d93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of first 3 features:\n",
      "[-4.31742554e-15  2.24606658e-15 -7.38359313e-16]\n",
      "Standard deviation of first 3 features:\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#First three features:\n",
    "\n",
    "first_three_features = X_train_scaled[:, :3]\n",
    "\n",
    "\n",
    "print(\"Mean of first 3 features:\")\n",
    "print(first_three_features.mean(0))\n",
    "\n",
    "\n",
    "print(\"Standard deviation of first 3 features:\")\n",
    "print(first_three_features.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c55c257b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy is: 0.9824561403508771\n",
      "The classification report is:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        42\n",
      "           1       0.99      0.99      0.99        72\n",
      "\n",
      "    accuracy                           0.98       114\n",
      "   macro avg       0.98      0.98      0.98       114\n",
      "weighted avg       0.98      0.98      0.98       114\n",
      "\n",
      "The confusion matric is: [[41  1]\n",
      " [ 1 71]]\n"
     ]
    }
   ],
   "source": [
    "logistic_regression = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "logistic_regression.fit(X_train_scaled,Y_train)\n",
    "\n",
    "y_predicted = logistic_regression.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(Y_test, y_predicted)\n",
    "\n",
    "classification_rp = classification_report(Y_test, y_predicted)\n",
    "\n",
    "confusion_mx = confusion_matrix(Y_test, y_predicted)\n",
    "\n",
    "print(\"The accuracy is:\" , accuracy)\n",
    "print(\"The classification report is:\" , classification_rp)\n",
    "print(\"The confusion matric is:\" , confusion_mx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f456df91",
   "metadata": {},
   "source": [
    "Interpretation: The model performs great in my opinion, having a 98.2% accuracy with high precision, recall, and F1-scores for both class groups, indicating it validates and correctly identifies both benign and malignant cases. The confusion matrix shows only 2 misclassifications, suggesting vey good reliability and great balance. \n",
    "\n",
    "Getting into the specifics: \n",
    "\n",
    "-  Precision: It tells how many of the model's positive predictions were actually right. here the score is 0.98 so that means there were very few false postive cases. \n",
    "\n",
    "-  Recall: It shows how many cases the model correctly identified. With a recall of around 0.98 and 0.99 it is also really good, which means it is able to identify all the true casses in each class group.\n",
    "\n",
    "-  F1-Score: It balances precision and recall. Since the score is around 0.98 to 0.99, we can interpret that model maintains high-quality predictions.\n",
    "\n",
    "- Confusion matrix: [[41 1], [1 71]] shows the model made just 2 errors: 1 false positive and 1 false negative. This confirms that the classifier is very accurate across both classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9c5bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.98245614 0.97368421 0.97368421 0.97368421 0.99115044]\n",
      "Mean accuracy: 0.9789318428815402\n",
      "Standard deviation: 0.006990390328940835\n"
     ]
    }
   ],
   "source": [
    "#Pipeline :\n",
    "\n",
    "pipelin = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_valuation_scores = cross_val_score(pipelin, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy scores:\", cross_valuation_scores)\n",
    "\n",
    "print(\"Mean accuracy:\", cross_valuation_scores.mean())\n",
    "\n",
    "print(\"Standard deviation:\", cross_valuation_scores.std())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b8cc5d",
   "metadata": {},
   "source": [
    "Comparison with step 3: \n",
    "\n",
    "Accuracy scores: 0.98 for the single train-test split and the accuracy for the cross validation was [0.9825, 0.9737, 0.9737, 0.9737, 0.9912]. The mean accuracy of the cross validation split was 97.89 percent. \n",
    "\n",
    "Interpretation: Even though the single split accuracy is higher than the cross validation split, it is not necessarily better as they both have different purposes, with the single-train-test split being for quick check on unseen data and the cross validation giving a more reliable estimate. \n",
    "\n",
    "The low standard deviation means that the model's performance is very stable and it behaves similarly across all 5 folds, with very little variation in accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbecbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final pipeline accuracy is: 0.9824561403508771\n"
     ]
    }
   ],
   "source": [
    "final_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_train, Y_train)\n",
    "\n",
    "final_predictions = final_pipeline.predict(X_test)\n",
    "\n",
    "final_accuracy = accuracy_score(Y_test, final_predictions)\n",
    "print(\"Final pipeline accuracy is:\", final_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a01c56",
   "metadata": {},
   "source": [
    "The pipeline accuracy on the 20% test set is 98.25%, which matches the accuracy from Part 3 when we manually scaled and trained a logistic regression model. \n",
    "\n",
    "This shows that the pipeline successfully automated , fitting and achieved equally good performance, while making the code cleaner and less error-prone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c21a17e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy on Test Set: 0.956140350877193\n",
      "Confusion Matrix: [[39  3]\n",
      " [ 2 70]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        42\n",
      "           1       0.96      0.97      0.97        72\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.95      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "random_forest_pipeline.fit(X_train, Y_train)\n",
    "random_forest_predictions = random_forest_pipeline.predict(X_test)\n",
    "\n",
    "random_forest_accuracy = accuracy_score(Y_test, random_forest_predictions)\n",
    "print(\"Random Forest Accuracy on Test Set:\", random_forest_accuracy)\n",
    "\n",
    "random_forest_cm = confusion_matrix(Y_test, random_forest_predictions)\n",
    "print(\"Confusion Matrix:\", random_forest_cm)\n",
    "\n",
    "random_forest_cr = classification_report(Y_test, random_forest_predictions)\n",
    "print(\"Classification Report:\", random_forest_cr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7024c336",
   "metadata": {},
   "source": [
    "Logistic Regression had higher accuracy (0.982) than Random Forest (0.956).  \n",
    "\n",
    "It also performed slightly better in precision and recall for both classes.  \n",
    "\n",
    "Random Forest was close but slightly weaker in detecting benign cases.  \n",
    "\n",
    "Overall, Logistic Regression was the better model on this dataset.\n",
    "\n",
    "The difference is not massive, but it suggests that Logistic Regression generalized slightly better on this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horizons25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
