{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8df4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Lung Cancer Assistant App\n",
    "# Using PyTorch model + Local LLM via LM Studio + Streamlit GUI\n",
    "\n",
    "import os\n",
    "import streamlit as st\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# -------- Configuration --------\n",
    "MODEL_PATH = \"lung_model.pth\"\n",
    "IMG_SIZE = 224\n",
    "\n",
    "data_log_file = \"prediction_log.csv\"\n",
    "\n",
    "# -------- Define CNN Model --------\n",
    "class LungCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LungCNN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 56 * 56, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "# -------- Image Transform --------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(),\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "# -------- Prediction --------\n",
    "def predict_image(image: Image.Image):\n",
    "    model = LungCNN()\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device('cpu')))\n",
    "    model.eval()\n",
    "    input_tensor = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_tensor)\n",
    "        _, pred = torch.max(outputs, 1)\n",
    "    return [\"benign\", \"malignant\", \"normal\"][pred.item()]\n",
    "\n",
    "# -------- Local LLM Integration (No OpenAI) --------\n",
    "def ask_local_llm(prompt):\n",
    "    try:\n",
    "        import requests\n",
    "        response = requests.post(\"http://localhost:1234/v1/chat/completions\", json={\n",
    "            \"model\": \"local-model\",\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful lung cancer diagnosis assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.7\n",
    "        })\n",
    "        return response.json()['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"Error contacting local LLM: {e}\"\n",
    "\n",
    "# -------- Log Date using sklearn (for demonstration, using pandas here) --------\n",
    "def log_prediction(prediction):\n",
    "    now = datetime.now()\n",
    "    log_entry = pd.DataFrame([[now.strftime(\"%Y-%m-%d %H:%M:%S\"), prediction]], columns=[\"timestamp\", \"prediction\"])\n",
    "    if os.path.exists(data_log_file):\n",
    "        log_entry.to_csv(data_log_file, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        log_entry.to_csv(data_log_file, index=False)\n",
    "\n",
    "# -------- View Logs --------\n",
    "def view_logs():\n",
    "    if os.path.exists(data_log_file):\n",
    "        st.subheader(\"ðŸ—‚ï¸ Prediction History\")\n",
    "        df = pd.read_csv(data_log_file)\n",
    "        st.dataframe(df)\n",
    "    else:\n",
    "        st.info(\"No predictions logged yet.\")\n",
    "\n",
    "# -------- Streamlit App --------\n",
    "st.set_page_config(page_title=\"Lung Cancer Assistant\", layout=\"centered\")\n",
    "st.title(\"ðŸ« Lung Cancer Prediction + AI Assistant\")\n",
    "\n",
    "menu = st.sidebar.radio(\"Go to:\", [\"ðŸ  Image Prediction\", \"ðŸ¤– Ask AI (LLM)\", \"ðŸ—‚ï¸ View Logs\", \"ðŸ“‹ About\"])\n",
    "\n",
    "if menu == \"ðŸ  Image Prediction\":\n",
    "    st.header(\"Upload a Chest CT Image\")\n",
    "    uploaded_file = st.file_uploader(\"Choose an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        image = Image.open(uploaded_file).convert(\"L\")\n",
    "        st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
    "        if st.button(\"Predict\"):\n",
    "            result = predict_image(image)\n",
    "            log_prediction(result)\n",
    "            st.success(f\"ðŸ§  Prediction: **{result.upper()}**\")\n",
    "\n",
    "elif menu == \"ðŸ¤– Ask AI (LLM)\":\n",
    "    st.header(\"AI Assistant for Lung Cancer Questions\")\n",
    "    question = st.text_area(\"Ask a question about lung cancer symptoms, risks, or treatment:\")\n",
    "    if st.button(\"Get Answer\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = ask_local_llm(question)\n",
    "        st.text_area(\"AI Response:\", response, height=250)\n",
    "\n",
    "elif menu == \"ðŸ—‚ï¸ View Logs\":\n",
    "    view_logs()\n",
    "\n",
    "elif menu == \"ðŸ“‹ About\":\n",
    "    st.markdown(\"\"\"\n",
    "    ### About This App\n",
    "    This app was built as a Personal Project by **Amogh Holla**. It consists of:\n",
    "\n",
    "    - âœ… A **deep learning model** trained on CT scan images to detect lung cancer (benign / malignant / normal)\n",
    "    - ðŸ’¬ A **locally running LLM (LLaMA via LM Studio)** that provides health insights and guidance\n",
    "    - ðŸ› ï¸ Built with **PyTorch**, **Streamlit**, and **LM Studio**\n",
    "    - ðŸ“… Logs all predictions by date\n",
    "    - ðŸ“Š Viewable history of predictions\n",
    "\n",
    "    > Powered by the IQ-OTH/NCCD Lung Cancer Dataset\n",
    "    \"\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "horizons25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
